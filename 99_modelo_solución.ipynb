{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ8MF-ozH1ha"
      },
      "source": [
        "Proyect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI_2hrF09OPf"
      },
      "source": [
        "#Solución Avanzada con LightGBM: Ingeniería de Características e Interacciones No Lineales\n",
        "\n",
        "1. Resumen de la Estrategia\n",
        "Esta solución implementa un modelo de clasificación basado en Gradient Boosting (LightGBM), diseñado específicamente para tabular datos socioeconómicos con alta eficiencia. A diferencia de enfoques tradicionales, esta estrategia prioriza la Ingeniería de Características (Feature Engineering) sobre la complejidad bruta del modelo, buscando capturar patrones de comportamiento mediante la interacción de variables.\n",
        "\n",
        "2. Innovaciones Clave (El \"Por qué\" funciona)\n",
        "Manejo Nativo de Categorías: Se utiliza la capacidad de LightGBM para procesar variables categóricas (como Departamento o Colegio) mediante algoritmos de partición óptima (Fisher), superando al tradicional One-Hot Encoding o Label Encoding que pierden información semántica.\n",
        "\n",
        "Captura de Interacciones Socioeconómicas: Se han creado variables sintéticas que cruzan dimensiones clave:\n",
        "\n",
        "TECH_SCORE (Índice de Riqueza Tecnológica): Agregación de activos (Internet + PC + Lavadora) para cuantificar el nivel de recursos del estudiante.\n",
        "\n",
        "EDU_x_ESTRATO (Interacción No Lineal): Multiplicación del nivel educativo de los padres por el estrato. Esto permite al modelo entender que el impacto de la educación parental se potencia en estratos altos, capturando una realidad social compleja de Colombia.\n",
        "\n",
        "Preservación de Jerarquía Ordinal: Variables como Nivel Educativo y Estrato fueron mapeadas numéricamente respetando su orden lógico (ej: Postgrado > Primaria), facilitando al árbol de decisión encontrar cortes de separación óptimos.\n",
        "\n",
        "3. Configuración del Entrenamiento\n",
        "Algoritmo: LightGBM (Histogram-based Gradient Boosting).\n",
        "\n",
        "Validación: StratifiedKFold (5 particiones) para garantizar que la distribución de las clases (Bajo, Medio, Alto) se mantenga constante en entrenamiento y validación.\n",
        "\n",
        "Optimización: Se utiliza un Learning Rate de 0.05 con Early Stopping, logrando un equilibrio entre convergencia rápida y capacidad de generalización para evitar el sobreajuste (overfitting)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb52qWjEGW_H",
        "outputId": "d06f041c-e831-40c3-be8f-f6817cedf83b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rlxutils\n",
            "  Downloading rlxutils-0.1.10.tar.gz (8.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from rlxutils) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rlxutils) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from rlxutils) (2.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from rlxutils) (1.5.2)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.12/dist-packages (from rlxutils) (4.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from rlxutils) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from rlxutils) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rlxutils) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rlxutils) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rlxutils) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rlxutils) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rlxutils) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rlxutils) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rlxutils) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->rlxutils) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->rlxutils) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->rlxutils) (2025.2)\n",
            "Requirement already satisfied: python-utils>=3.8.1 in /usr/local/lib/python3.12/dist-packages (from progressbar2->rlxutils) (3.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->rlxutils) (1.17.0)\n",
            "Requirement already satisfied: typing_extensions>3.10.0.2 in /usr/local/lib/python3.12/dist-packages (from python-utils>=3.8.1->progressbar2->rlxutils) (4.15.0)\n",
            "Building wheels for collected packages: rlxutils\n",
            "  Building wheel for rlxutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rlxutils: filename=rlxutils-0.1.10-py3-none-any.whl size=11100 sha256=eb3352a59a3db1229b85f911a9117ec164fdaf4ae2214d2567d1ae9153ebf4d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/8f/e3/7c998c7a46a028383fd3c53494f18d81d52b7368c6b33e4ab6\n",
            "Successfully built rlxutils\n",
            "Installing collected packages: rlxutils\n",
            "Successfully installed rlxutils-0.1.10\n"
          ]
        }
      ],
      "source": [
        "!pip install rlxutils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6cy1lh09OBm",
        "outputId": "0f395306-7e37-4131-d849-b3af31a8c3a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Downloading udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to /content\n",
            "  0% 0.00/29.9M [00:00<?, ?B/s]\n",
            "100% 29.9M/29.9M [00:00<00:00, 388MB/s]\n",
            "Archive:  udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip\n",
            "  inflating: data/submission_example.csv  \n",
            "  inflating: data/test.csv           \n",
            "  inflating: data/train.csv          \n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "import os\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n",
        "!chmod 600 ./kaggle.json\n",
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n",
        "!unzip udea*.zip -d data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GheDvfvO-1PP",
        "outputId": "48a90d25-2d35-427d-b57c-fc2a1bcc71a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTAwSjdUAIEp",
        "outputId": "5613c58f-d2d1-44e8-9866-6684f0dc1cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "import os\n",
        "\n",
        "# Configura la ruta del token\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n",
        "\n",
        "# Permisos de seguridad para el archivo\n",
        "!chmod 600 ./kaggle.json\n",
        "\n",
        "# Descarga el dataset del concurso\n",
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXCHn6PENQ7W"
      },
      "source": [
        "#Modelo LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kufzKKq4tgvp",
        "outputId": "ac09d3c1-cd6d-4af9-c9dd-2509f5e0ea02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Librerías cargadas correctamente.\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm pandas scikit-learn scipy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import mode\n",
        "import warnings\n",
        "\n",
        "# Configuración visual\n",
        "pd.set_option('display.max_columns', None)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Librerías cargadas correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4BCDfHRw7p-"
      },
      "source": [
        "#Mapeos y función de preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q6Wotnmaw8CE"
      },
      "outputs": [],
      "source": [
        "# 2. DEFINICIÓN Y PREPROCESAMIENTO \"TURBO\"\n",
        "\n",
        "# Mapas\n",
        "edu_map = {\n",
        "    'No sabe': 0, 'No Aplica': 0, 'Ninguno': 0,\n",
        "    'Primaria incompleta': 1, 'Primaria completa': 2,\n",
        "    'Secundaria (Bachillerato) incompleta': 3, 'Secundaria (Bachillerato) completa': 4,\n",
        "    'Técnica o tecnológica incompleta': 5, 'Técnica o tecnológica completa': 6,\n",
        "    'Educación profesional incompleta': 7, 'Educación profesional completa': 8,\n",
        "    'Postgrado': 9\n",
        "}\n",
        "estrato_map = {'Estrato 1': 1, 'Estrato 2': 2, 'Estrato 3': 3, 'Estrato 4': 4, 'Estrato 5': 5, 'Estrato 6': 6, 'Sin Estrato': 0}\n",
        "target_map = {'bajo': 0, 'medio-bajo': 1, 'medio-alto': 2, 'alto': 3}\n",
        "inv_target_map = {v: k for k, v in target_map.items()}\n",
        "\n",
        "def preprocess_turbo(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1. Numéricos básicos\n",
        "    cols_edu = ['F_EDUCACIONPADRE', 'F_EDUCACIONMADRE']\n",
        "    for col in cols_edu:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].map(edu_map).fillna(1)\n",
        "\n",
        "    if 'F_ESTRATOVIVIENDA' in df.columns:\n",
        "        df['F_ESTRATOVIVIENDA'] = df['F_ESTRATOVIVIENDA'].map(estrato_map).fillna(2)\n",
        "\n",
        "    # 2. Binarias\n",
        "    binarias = ['F_TIENEINTERNET', 'F_TIENELAVADORA', 'F_TIENECOMPUTADOR', 'E_PAGOMATRICULAPROPIO']\n",
        "    for col in binarias:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].map({'Si': 1, 'No': 0, 'S': 1, 'N': 0}).fillna(0)\n",
        "\n",
        "    # --- 3. INGENIERÍA DE CARACTERÍSTICAS (MEJORAS CLAVE) ---\n",
        "\n",
        "    # Indice Tecnológico (0 a 3)\n",
        "    cols_tech = ['F_TIENEINTERNET', 'F_TIENECOMPUTADOR', 'F_TIENELAVADORA']\n",
        "    # Verificamos que existan antes de sumar\n",
        "    exist_tech = [c for c in cols_tech if c in df.columns]\n",
        "    df['TECH_SCORE'] = df[exist_tech].sum(axis=1)\n",
        "\n",
        "    # Max Educación Padres\n",
        "    if 'F_EDUCACIONPADRE' in df.columns and 'F_EDUCACIONMADRE' in df.columns:\n",
        "        df['MAX_PADRES'] = df[['F_EDUCACIONPADRE', 'F_EDUCACIONMADRE']].max(axis=1)\n",
        "        # Interacción: Educación x Estrato (Poderoso predictor)\n",
        "        if 'F_ESTRATOVIVIENDA' in df.columns:\n",
        "            df['EDU_x_ESTRATO'] = df['MAX_PADRES'] * df['F_ESTRATOVIVIENDA']\n",
        "\n",
        "    # Interacción: Tecnología x Estrato\n",
        "    if 'F_ESTRATOVIVIENDA' in df.columns:\n",
        "        df['TECH_x_ESTRATO'] = df['TECH_SCORE'] * df['F_ESTRATOVIVIENDA']\n",
        "\n",
        "    # 4. Categorías para LightGBM\n",
        "    cat_cols = df.select_dtypes(include=['object']).columns\n",
        "    for col in cat_cols:\n",
        "        if col != 'RENDIMIENTO_GLOBAL':\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    if 'ID' in df.columns:\n",
        "        df = df.drop('ID', axis=1)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67y9uLl_O8eh"
      },
      "source": [
        "#Carga y procesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96LWJIDdufBF",
        "outputId": "2fd50ec0-081f-4e59-87fa-9208b6b2cd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando...\n",
            "Procesando...\n",
            "Listos. Columnas generadas: 23\n"
          ]
        }
      ],
      "source": [
        "print(\"Cargando...\")\n",
        "train = pd.read_csv('data/train.csv')\n",
        "test = pd.read_csv('data/test.csv')\n",
        "test_ids = test['ID']\n",
        "\n",
        "print(\"Procesando...\")\n",
        "train_proc = preprocess_turbo(train)\n",
        "test_proc = preprocess_turbo(test)\n",
        "\n",
        "X = train_proc.drop('RENDIMIENTO_GLOBAL', axis=1)\n",
        "y = train_proc['RENDIMIENTO_GLOBAL'].map(target_map)\n",
        "X_test = test_proc[X.columns]\n",
        "\n",
        "print(f\"Listos. Columnas generadas: {len(X.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FgFcqQ6uoTD"
      },
      "source": [
        "#Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jnhrz25urSN",
        "outputId": "f22e1d07-a01c-472c-bb4e-0efbb00ede1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando Modelo Turbo (5 Folds)...\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.233059 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1673\n",
            "[LightGBM] [Info] Number of data points in the train set: 554000, number of used features: 22\n",
            "[LightGBM] [Info] Start training from score -1.387096\n",
            "[LightGBM] [Info] Start training from score -1.391216\n",
            "[LightGBM] [Info] Start training from score -1.395033\n",
            "[LightGBM] [Info] Start training from score -1.371986\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[430]\tvalid_0's multi_logloss: 1.18838\n",
            "Fold 1: 0.44139\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182831 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1680\n",
            "[LightGBM] [Info] Number of data points in the train set: 554000, number of used features: 23\n",
            "[LightGBM] [Info] Start training from score -1.387089\n",
            "[LightGBM] [Info] Start training from score -1.391216\n",
            "[LightGBM] [Info] Start training from score -1.395033\n",
            "[LightGBM] [Info] Start training from score -1.371993\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[397]\tvalid_0's multi_logloss: 1.18736\n",
            "Fold 2: 0.43934\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.173315 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1680\n",
            "[LightGBM] [Info] Number of data points in the train set: 554000, number of used features: 23\n",
            "[LightGBM] [Info] Start training from score -1.387089\n",
            "[LightGBM] [Info] Start training from score -1.391216\n",
            "[LightGBM] [Info] Start training from score -1.395033\n",
            "[LightGBM] [Info] Start training from score -1.371993\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[395]\tvalid_0's multi_logloss: 1.18871\n",
            "Fold 3: 0.43972\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157148 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1673\n",
            "[LightGBM] [Info] Number of data points in the train set: 554000, number of used features: 22\n",
            "[LightGBM] [Info] Start training from score -1.387089\n",
            "[LightGBM] [Info] Start training from score -1.391216\n",
            "[LightGBM] [Info] Start training from score -1.395033\n",
            "[LightGBM] [Info] Start training from score -1.371993\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[353]\tvalid_0's multi_logloss: 1.18959\n",
            "Fold 4: 0.44004\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.159661 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1679\n",
            "[LightGBM] [Info] Number of data points in the train set: 554000, number of used features: 22\n",
            "[LightGBM] [Info] Start training from score -1.387096\n",
            "[LightGBM] [Info] Start training from score -1.391216\n",
            "[LightGBM] [Info] Start training from score -1.395026\n",
            "[LightGBM] [Info] Start training from score -1.371993\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[342]\tvalid_0's multi_logloss: 1.1895\n",
            "Fold 5: 0.43935\n",
            "--> Promedio: 0.43997\n"
          ]
        }
      ],
      "source": [
        "# 4. ENTRENAMIENTO VELOZ\n",
        "clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=4,\n",
        "    n_estimators=1200,    # Reducido de 3000 a 1200 (Suficiente)\n",
        "    learning_rate=0.05,   # SUBIDO: Más rápido\n",
        "    num_leaves=40,        # Un poco más complejo para capturar detalles\n",
        "    max_depth=-1,\n",
        "    min_child_samples=30,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.7,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Volvemos a 5 Folds (Más que suficiente y mucho más rápido)\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "preds_test_folds = []\n",
        "scores = []\n",
        "\n",
        "print(\"Entrenando Modelo Turbo (5 Folds)...\")\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    clf.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)] # Silencioso\n",
        "    )\n",
        "\n",
        "    acc = accuracy_score(y_val, clf.predict(X_val))\n",
        "    scores.append(acc)\n",
        "    preds_test_folds.append(clf.predict(X_test))\n",
        "\n",
        "    print(f\"Fold {fold+1}: {acc:.5f}\")\n",
        "\n",
        "print(f\"--> Promedio: {np.mean(scores):.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vksDltru6qf"
      },
      "source": [
        "#Generar Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_3mZKxOu7KY",
        "outputId": "79334924-59a9-40f0-c15e-01b266ece8b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando archivo...\n",
            "Archivo 'submission_turbo_lgbm.csv' creado.\n"
          ]
        }
      ],
      "source": [
        "# 5. GUARDAR\n",
        "print(\"Generando archivo...\")\n",
        "preds_matrix = np.column_stack(preds_test_folds)\n",
        "final_preds_idx, _ = mode(preds_matrix, axis=1)\n",
        "final_preds_idx = final_preds_idx.ravel()\n",
        "\n",
        "final_preds_str = [inv_target_map[x] for x in final_preds_idx]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': final_preds_str\n",
        "})\n",
        "\n",
        "submission.to_csv('submission_turbo_lgbm.csv', index=False)\n",
        "print(\"Archivo 'submission_turbo_lgbm.csv' creado.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit \\\n",
        "  -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia \\\n",
        "  -f submission_turbo_lgbm.csv \\\n",
        "  -m \"Submission LightGBM Turbo + Interacciones\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtsqwGmcyfxv",
        "outputId": "447f0c4c-a1b0-4f0a-8c2f-5ea692504c10"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 4.05M/4.05M [00:01<00:00, 3.36MB/s]\n",
            "Successfully submitted to UDEA/ai4eng 20252 - Pruebas Saber Pro Colombia"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "223oOVvmRC2z"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}